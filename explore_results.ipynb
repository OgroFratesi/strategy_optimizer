{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import ta\n",
    "import decimal\n",
    "import tqdm\n",
    "import yfinance as yf\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up S3 client\n",
    "s3 = boto3.client('s3',\n",
    "        aws_access_key_id=,\n",
    "        aws_secret_access_key=)\n",
    "\n",
    "# Define S3 bucket and prefix where CSV files are stored\n",
    "bucket_name = 'backtester-bucket-results'\n",
    "prefix = 'final_results/'\n",
    "\n",
    "file_name = \n",
    "# Get list of CSV files in the bucket with the specified prefix\n",
    "objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "csv_files = [obj['Key'] for obj in objects['Contents'] if file_name in obj['Key']]\n",
    "\n",
    "# Load CSV files into a list of dataframes\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=file)\n",
    "    dfs.append(pd.read_csv(obj['Body']))\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "290a0437a5503a70b5074cc0968a0efcb1f357d9f757b8a173cff144f7201fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
